{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'C:\\\\Users\\\\User\\\\Documents\\\\citations-network-analysis\\\\Analyzers\\\\..\\\\Data\\\\citations_to_names.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-444a94eac124>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mAnalyzers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEdgeDataAnalyzers\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0meda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEdgeDataAnalyzers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEdgeDataAnalyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEdgeDataAnalyzers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCentralityAnalyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mgv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEdgeDataAnalyzers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphVisualizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\citations-network-analysis\\Analyzers\\EdgeDataAnalyzers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mEdgeDataAnalyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseAnalyzer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_cases_citing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcase_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcase_title\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\citations-network-analysis\\Analyzers\\BaseAnalyzer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         self.citations_to_names = pd.read_csv(PATH_TO_CITES_REF,\n\u001b[1;32m---> 11\u001b[1;33m         index_col = 0, header=None).to_dict()[1] # maps citations to case names\n\u001b[0m\u001b[0;32m     12\u001b[0m         self.ids_to_citations = pd.read_csv(PATH_TO_IDS_REF,\n\u001b[0;32m     13\u001b[0m         index_col = 0, header=None).to_dict()[1] # maps ids to case citations\n",
      "\u001b[1;32m~\\py36-64\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\py36-64\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\py36-64\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 818\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\py36-64\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1050\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\py36-64\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'C:\\\\Users\\\\User\\\\Documents\\\\citations-network-analysis\\\\Analyzers\\\\..\\\\Data\\\\citations_to_names.csv' does not exist"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Analyzers import EdgeDataAnalyzers\n",
    "eda = EdgeDataAnalyzers.EdgeDataAnalyzer()\n",
    "ca = EdgeDataAnalyzers.CentralityAnalyzer()\n",
    "gv = EdgeDataAnalyzers.GraphVisualizer()\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "from Analyzers import MetaDataAnalyzer\n",
    "mda = MetaDataAnalyzer.MetaDataAnalyzer()\n",
    "import networkx as nx\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv('Data/transformed_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "global stats - mean, sd: cases per topic (top 20 and others), word count, citations received, citations given, citations received per word, citations given per word, num_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_to_tabulate=['judgment_word_count',\n",
    "                    'num_cited_cases',\n",
    "                    'num_citing_cases',\n",
    "                    'cites_per_000_word',\n",
    "                 ]\n",
    "global_stats = np.round(mda.tabulate_global_stats(meta_df,\n",
    "    cols_to_tabulate=cols_to_tabulate), 4)\n",
    "\n",
    "global_stats.columns = ['All Cases']\n",
    "global_stats.loc['_size'] = meta_df.shape[0]\n",
    "global_stats.index = pd.Series(global_stats.index).apply(eda.readify_varnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine with stats by bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bench_stats = meta_df.groupby('bench').agg({'judgment_word_count': [np.mean,np.std],\n",
    "                         'num_cited_cases': [np.mean, np.std],\n",
    "                         'num_citing_cases': [np.mean, np.std],\n",
    "                         'cites_per_000_word': [np.mean, np.std, np.size]\n",
    "}).apply(np.round, axis=1, args=(4,)).transpose()[['yong','chan','menon']]\n",
    "for x_i in bench_stats.index:\n",
    "    if x_i[-1] == 'std':\n",
    "        bench_stats.loc[x_i] = bench_stats.loc[x_i].apply(lambda x: '('+str(np.round(x,4))+')')\n",
    "bench_stats = bench_stats.reset_index()\n",
    "bench_stats.index = bench_stats['level_0'] + '_' +bench_stats['level_1']\n",
    "bench_stats.index.name = None\n",
    "bench_stats.index = pd.Series(bench_stats.index).apply(eda.readify_varnames)\n",
    "bench_stats = bench_stats.drop(['level_0', 'level_1'], axis=1)\n",
    "bench_stats.columns = [x.title()+' Bench' for x in bench_stats.columns]\n",
    "bench_stats['Overall'] = global_stats\n",
    "bench_stats.loc['Years In Sample'] = [6,6,6,18]\n",
    "bench_stats.to_latex('Tables/bench_stats.tex')\n",
    "bench_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yearly_stats = np.round(eda.tabulate_time_series(meta_df, \n",
    "                                        ['judgment_word_count','num_cited_cases', 'num_citing_cases', 'cites_per_000_word',],\n",
    "                                        'decision_year'), 4)\n",
    "yearly_stats = eda.format_groupby_for_pub(yearly_stats)\n",
    "yearly_stats.columns.name = 'Year Decided'\n",
    "yearly_stats.to_latex('Tables/yearly_stats.tex')\n",
    "yearly_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_values_on_bars(axs):\n",
    "    def _show_on_single_plot(ax):        \n",
    "        for p in ax.patches:\n",
    "            _x = p.get_x() + p.get_width() + 7\n",
    "            _y = p.get_y()\n",
    "            value = '{:.0f}'.format(p.get_width())\n",
    "            ax.text(_x, _y, value, ha=\"center\") \n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _show_on_single_plot(ax)\n",
    "    else:\n",
    "        _show_on_single_plot(axs)\n",
    "\n",
    "topic_cols = [col for col in meta_df.columns if col.startswith('has_topic')]\n",
    "topic_counts = meta_df[topic_cols].sum().sort_values(ascending=True)\n",
    "topic_counts.index = [x.replace('has_topic','').replace('_', ' ').title().strip() for x in topic_counts.index]\n",
    "plt.figure(figsize=(10,12))\n",
    "ax = topic_counts.plot(kind='barh', color='skyblue')\n",
    "\n",
    "### stuff to dejunk the plot\n",
    "show_values_on_bars(ax)\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_visible(False)\n",
    "plt.tick_params(top='off', bottom='off', left='off', right='off', labelleft='on', labelbottom='off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Images/charts/global_topic_counts.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_freq_topics = pd.Series(topic_counts.sort_values(ascending=False).index[0:10].values)\n",
    "most_freq_topics_colnames = most_freq_topics.apply(lambda x: ('has_topic_'+x.lower()).strip())\n",
    "topic_colnames = ['has_topic_civil procedure','has_topic_contract','has_topic_criminal procedure and sentencing',\n",
    "                  'has_topic_tort', 'has_topic_criminal law', 'has_topic_evidence', 'has_topic_companies',\n",
    "                  'has_topic_words and phrases', 'has_topic_words and phrases', 'has_topic_courts and jurisdiction'\n",
    "                 ]\n",
    "mda.tabulate_topical_stats(meta_df, cols_to_tabulate, topic_colnames).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,4))\n",
    "plt.subplot(131)\n",
    "plt.scatter(meta_df['judgment_word_count'] /1000, meta_df['num_citing_cases'])\n",
    "plt.xlabel('Judgment Word Count (\\'000s)')\n",
    "plt.ylabel('Inward Citations')\n",
    "plt.title('(1)')\n",
    "plt.subplot(132)\n",
    "plt.scatter(meta_df['judgment_word_count'] /1000, meta_df['num_cited_cases'])\n",
    "plt.ylabel('Outward Citations')\n",
    "plt.xlabel('Judgment Word Count (\\'000s)')\n",
    "plt.title('(2)')\n",
    "plt.subplot(133)\n",
    "plt.scatter(meta_df['num_citing_cases'], meta_df['num_cited_cases'])\n",
    "plt.xlabel('Inward Citations')\n",
    "plt.ylabel('Outward Citations')\n",
    "plt.title('(3)')\n",
    "plt.subplots_adjust(wspace=0.30)\n",
    "plt.savefig('Images/cite_scatters.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_df[cols_to_tabulate].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = pd.DataFrame()\n",
    "for topic in topic_colnames:\n",
    "    topic_data =  meta_df.groupby(topic)[cols_to_tabulate].agg([np.mean, np.std, np.size])\n",
    "    has_topic_data = topic_data.loc[1]\n",
    "    table[topic] = has_topic_data\n",
    "\n",
    "topic_stats = eda.format_groupby_for_pub(np.round(table,4)).transpose()\n",
    "#drop extra obs columns as we apply np.count every time\n",
    "topic_stats.columns = ['drop' if x == 'Observations In Sample' else x for x in topic_stats.columns[:-1]] + ['Observations In Sample']\n",
    "topic_stats = topic_stats.drop('drop', axis=1)\n",
    "\n",
    "#all this work to properly place std below the respective columns\n",
    "topic_stats.columns = ['std_{}'.format(topic_stats.columns[i-1]) if x == '' else x for i, x in enumerate(topic_stats.columns)]\n",
    "sds = topic_stats[[col for col in topic_stats if col.startswith('std')]]\n",
    "topic_stats = topic_stats.drop([col for col in topic_stats if col.startswith('std')], axis=1)\n",
    "for topic in topic_colnames:\n",
    "    for stat in topic_stats:\n",
    "        if stat.lower().startswith('obs'):\n",
    "            continue\n",
    "        topic_stats.loc[topic+'_std', stat] = sds.loc[topic, 'std_'+stat]\n",
    "\n",
    "# need to sort them back in place so they appear correctly\n",
    "topic_stats = topic_stats.sort_index().fillna(method='ffill')\n",
    "topic_stats['colFromIndex'] = topic_stats.index\n",
    "topic_stats = topic_stats.sort_values(['Observations In Sample', 'colFromIndex'], ascending=True).drop('colFromIndex', axis=1)\n",
    "\n",
    "# finally, std are right...\n",
    "topic_stats['Observations In Sample'] = topic_stats['Observations In Sample'].astype(int)\n",
    "topic_stats['Observations In Sample'] = ['' if (i+1)%2==0 else val for i, val in enumerate(topic_stats['Observations In Sample'])]\n",
    "topic_stats.index = [eda.readify_varnames(x) for x in topic_stats.index]\n",
    "topic_stats.to_latex('Tables/topic_stats.tex')\n",
    "topic_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_df.groupby('has_topic_tort')[cols_to_tabulate].agg([np.mean, np.std, np.size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mda.get_perc_with_sole_topic(meta_df, 'has_topic_contract')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time series plot of word count, num_cases, num_cited, cites_per_word, mean_cited_ages\n",
    "\n",
    "note that graph is not used in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standardize(pd_srs):\n",
    "    return (pd_srs - pd_srs.mean()) / pd_srs.std()\n",
    "\n",
    "yearly = meta_df.groupby('decision_year')[['judgment_word_count','num_cited_cases', 'num_citing_cases', 'cites_per_000_word',]].agg(np.mean)\n",
    "fig, ax = plt.subplots(figsize=(11,7))\n",
    "ax1 = yearly['judgment_word_count'].plot(ax=ax, label='Judgment Word Count (left axis)')\n",
    "ax1.set_ylabel('Word Count')\n",
    "ax2 = yearly['num_cited_cases'].plot(ax=ax, secondary_y=True, linestyle='--')\n",
    "ax2 = yearly['num_citing_cases'].plot(ax=ax, secondary_y=True, linestyle='-.')\n",
    "ax2 = yearly['cites_per_000_word'].plot(ax=ax, secondary_y=True, linestyle=':')\n",
    "plt.legend((ax1.lines[0],ax2.lines[0], ax2.lines[1], ax2.lines[2]), ('Judgment Word Count (left axis)',\n",
    "                                                      'No. Outgoing Citations (right axis)',\n",
    "                                                      'No. Incoming Citations (right axis)',\n",
    "                                                      'Outgoing Citations Per Thousand Words (right axis)',))\n",
    "ax1.set_xlabel('Year Decided')\n",
    "ax2.set_ylabel('No. Citations')\n",
    "# this is simply to make the years display as ints\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.tight_layout()\n",
    "plt.savefig('Images/charts/wordcount_time_series.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To produce lagged correlations presented in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,4):\n",
    "    print(yearly['num_citing_cases'].corr(\n",
    "        yearly['judgment_word_count'].shift(-i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "heatmap of case load presented as Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14,8))\n",
    "hmap1, ax1 = mda.plot_yearmonth_map(ax1, meta_df, 'judgment_word_count', with_rowmeans=True, with_colmeans=True, cbar_kws={'shrink':0.5})\n",
    "hmap2, ax2 = mda.plot_yearmonth_map(ax2, meta_df, 'case_title', np.size, with_rowmeans=True, with_colmeans=True, cbar_kws={'shrink':0.5})\n",
    "ax2.set_ylabel('')\n",
    "ax1.set_title('Average Judgment Word Counts', y = 1.125)\n",
    "ax2.set_title('Average Number of Cases', y = 1.125)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Images/charts/num_cases_word_heat.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_df[(meta_df['has_topic_civil procedure'] == 1) | (meta_df['has_topic_criminal procedure and sentencing']==1)][[col for col in meta_df.columns if col.startswith('has_topic')]].sum(axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mda.get_stats_by_topic_num(meta_df, 'evidence', 1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cp_cases = pd.DataFrame(meta_df[(meta_df['has_topic_civil procedure'] == 1)\n",
    "                                |(meta_df['has_topic_criminal procedure and sentencing']==1)\n",
    "                                |(meta_df['has_topic_criminal law']==1)\n",
    "                               |(meta_df['has_topic_tort']==1)\n",
    "                               |(meta_df['has_topic_evidence']==1)]\n",
    "                       [['has_topic_civil procedure', 'has_topic_evidence', 'has_topic_contract',\n",
    "                        'has_topic_criminal procedure and sentencing',\n",
    "                        'has_topic_criminal law','num_topics']+cols_to_tabulate])\n",
    "# WARNING THE NEXT LINE CAUSES FAULTY LOGIC AND WRONG STATISTICS BECAUSE IT DOES NOT ACCOUNT FOR MULTIPLE TOPICS\n",
    "cp_cases['topic'] = cp_cases[[col for col in cp_cases.columns if col.startswith('has_topic')]].idxmax(axis=1)\n",
    "cp_cases['num_topics_binary'] = cp_cases['num_topics'].apply(lambda x:1 if x == 1 else '>1')\n",
    "topic_num_stats = cp_cases.groupby(('topic','num_topics_binary')).agg([np.mean, np.std, np.size])[['judgment_word_count', 'num_cited_cases', 'cites_per_000_word']]\n",
    "topic_num_stats = topic_num_stats.drop(('judgment_word_count', 'size'), axis=1)\n",
    "topic_num_stats = topic_num_stats.drop(('num_cited_cases', 'size'), axis=1)\n",
    "topic_num_stats.columns = pd.MultiIndex.from_arrays([['Word Count', 'Word Count', 'outcites','outcites','Outward Citations Per \\'000 Words', 'Outward Citations Per \\'000 Words', 'No. Obs.'],\n",
    "                                                    ['mean', 'std', 'mean', 'std', 'mean', 'std','']])\n",
    "topic_num_stats = eda.format_groupby_for_pub(np.round(topic_num_stats.transpose(), 4))\n",
    "topic_num_stats.columns.names = ('Subject Matter', 'No. Subjects')\n",
    "topic_num_stats = topic_num_stats.rename(columns={x:eda.readify_varnames(x) for x in topic_num_stats.columns.get_level_values(0)}, level=0)\n",
    "topic_num_stats = topic_num_stats.rename({'No. Obs._':'No. Obs.'},axis=0)\n",
    "topic_num_stats.to_latex('Tables/topic_num_stats.tex', multicolumn_format='r')\n",
    "topic_num_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall graph plots. Only the directed graph global plot is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = gv.prepare_graph(edge_df, 'citing_id', 'cited_id', create_using=nx.Graph())\n",
    "g, importance = gv.prepare_plot(g, importance_thresh=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax = gv.plot_graph(ax, g, importance, size_multiplier=5, with_labels=True, edge_kwargs={'width':0.5,'alpha':0.25})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_thresh = 1\n",
    "dg = gv.prepare_graph(edge_df, 'citing_id', 'cited_id', create_using=nx.DiGraph())\n",
    "sub_dg, sub_importance = gv.prepare_plot(dg, importance_thresh=imp_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "gv.plot_graph(ax, sub_dg, sub_importance, size_multiplier=25, edge_kwargs={'width':0.5,'alpha':0.25})\n",
    "plt.tight_layout()\n",
    "plt.savefig('Images/graphs/overall_directed_imp_thresh_{}.png'.format(imp_thresh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Central cases - overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_cent = ca.get_centrality_df(dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_rank_scores = ca.get_rank_scores(all_cent, meta_df, 'authority_score').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_rank_scores.case_title.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "format_rank_scores(all_rank_scores.head(5)).to_latex('Tables/global_rankings.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "citing_spandeck_outdeg = eda.get_scores_for_cases_citing_case(775, 'hub_score', edge_df, all_cent)\n",
    "citing_zurich_outdeg = eda.get_scores_for_cases_citing_case(987, 'hub_score', edge_df, all_cent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the 9 cases citing Zurich that aren't tagged contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eda.find_cases_citing(987, edge_df[edge_df['citing_has_topic_contract']==0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the top cases by each measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_central_cases = eda.convert_id_df_to_case_names(ca.get_top_k_per_measure(all_cent, k = 1, cols_to_exclude=[]), True)\n",
    "all_central_cases = all_central_cases[['in_degree']+ca.get_measures()]\n",
    "all_central_cases = all_central_cases.drop(['in_degree_cent', 'out_degree_cent'], axis=1)\n",
    "all_central_cases.columns = np.vectorize(eda.readify_varnames)(all_central_cases.columns.values)\n",
    "all_central_cases = all_central_cases.rename({0:'Top Case'},axis=0).transpose()\n",
    "all_central_cases.to_latex('Tables/global_top_cases.tex')\n",
    "all_central_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Analyzers import EdgeDataAnalyzers\n",
    "eda = EdgeDataAnalyzers.EdgeDataAnalyzer()\n",
    "ca = EdgeDataAnalyzers.CentralityAnalyzer()\n",
    "gv = EdgeDataAnalyzers.GraphVisualizer()\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "from Analyzers import MetaDataAnalyzer\n",
    "mda = MetaDataAnalyzer.MetaDataAnalyzer()\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_5_yrly = ca.get_top_k_over_time(edge_df, 'authority_score', '20000101', '20171231', 'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_5_yrly.columns = [str(col) for col in top_5_yrly.columns]\n",
    "top_5_yrly#.applymap(eda.get_case_name_from_id_num) uncomment to get names instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_relevant_subset(edge_df, topic_name):\n",
    "    if not topic_name:\n",
    "        return edge_df.copy()\n",
    "    else:\n",
    "        return edge_df[edge_df['citing_has_topic_'+topic_name]==1].copy()\n",
    "\n",
    "def get_key_cases_ts(edge_df, rank_scores, key_cases, topic_name=''):\n",
    "    relevant_subset = get_relevant_subset(edge_df, topic_name)\n",
    "    case_time_series = {}\n",
    "    for case in key_cases:\n",
    "        case_name = eda.get_case_name_from_id_num(case)\n",
    "        print('Getting scores for case {}'.format(case_name))\n",
    "        start, end = '20000101', '20171231'\n",
    "        case_measures_over_time = ca.get_all_case_measures_over_time(\n",
    "            relevant_subset, case, '20000101', '20171231', \n",
    "            measures_to_include = [\n",
    "                'in_degree_cent',\n",
    "                'hub_score',\n",
    "                'authority_score',\n",
    "            ]\n",
    "        )\n",
    "        case_time_series[case] = case_measures_over_time\n",
    "    return case_time_series\n",
    "    \n",
    "def get_topic_rank_scores(edge_df, meta_df, topic_name=''):\n",
    "    relevant_subset = get_relevant_subset(edge_df, topic_name)    \n",
    "    topic_dg = gv.prepare_graph(relevant_subset, 'citing_id', 'cited_id', create_using=nx.DiGraph())\n",
    "    topic_central_df = ca.get_centrality_df(topic_dg)\n",
    "    rank_scores = ca.get_rank_scores(topic_central_df, meta_df, 'authority_score')\n",
    "    return rank_scores    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = pd.read_csv('test_sgca_regex.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp[(temp['ls_cited_cases'].notnull()) & (temp['ls_cited_cases'] != '[]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_cases = (987,737,722)\n",
    "contract_rankings, contract_ts = analyze_one_topic(edge_df, meta_df, '', 'contract', key_cases, with_prompts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "format_rank_scores(contract_rankings).head(5).to_latex('Tables/contract_rankings.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,5))\n",
    "styles = ('-', '--', ':')\n",
    "labels = ('Zurich', 'Sembcorp', 'Sandar')\n",
    "for i, case in enumerate(key_cases):\n",
    "    contract_ts[case]['authority_score'].plot(label=labels[i], linestyle=styles[i], color='darkblue')\n",
    "    plt.legend()\n",
    "\n",
    "plt.ylabel('Authority Score')\n",
    "plt.xlabel('Year')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Images/zurich_ts.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_cases = (987,737,722)\n",
    "_, global_ts = analyze_one_topic(edge_df, meta_df, '', '', key_cases, with_prompts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "styles = ('-', '--', ':')\n",
    "labels = ('Zurich', 'Sembcorp', 'Sandar')\n",
    "for i, case in enumerate(key_cases):\n",
    "    global_ts[case]['authority_score'].plot(label=labels[i], linestyle=styles[i], color='darkblue')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "find_cases_citing(722, edge_df[edge_df['citing_has_topic_contract']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "find_cases_citing(987, edge_df[edge_df['citing_has_topic_contract']==1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def analyze_one_topic(edge_df, save_folder_name, topic_colname='', with_prompts=True):\n",
    "    \n",
    "    BASE_PATH = 'Images/{}/{}/{}_{}'\n",
    "    for folder_type in ('graphs', 'charts', 'tables'):\n",
    "        folder = 'Images/{}/{}'.format(folder_type, save_folder_name)\n",
    "        if not os.path.isdir(folder):\n",
    "            os.mkdir(folder)\n",
    "    \n",
    "    if not topic_colname:\n",
    "        print('Analyzing global data as no topic was supplied')\n",
    "        topic_df = edge_df.copy()\n",
    "    else:\n",
    "        topic_df = edge_df[edge_df[topic_colname]==1].copy()\n",
    "    \n",
    "    print('Plotting overall graph as direct and undirected graphs...')\n",
    "    topic_dg = gv.prepare_graph(topic_df, 'citing_id', 'cited_id', plot_using='dg')\n",
    "    topic_g = gv.prepare_graph(topic_df, 'citing_id', 'cited_id', plot_using='g')\n",
    "    \n",
    "    topic_dg, topic_dg_importance = gv.prepare_plot(topic_dg, importance_thresh=4)\n",
    "    topic_g, topic_g_importance = gv.prepare_plot(topic_g, importance_thresh=4)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10,10))    \n",
    "    ax = gv.plot_graph(ax, topic_g, topic_g_importance, with_labels=True)\n",
    "    plt.savefig(BASE_PATH.format('graphs', save_folder_name, save_folder_name, 'overall_undirected.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    ax = gv.plot_graph(ax, topic_dg, topic_dg_importance, with_labels=True)\n",
    "    plt.savefig(BASE_PATH.format('graphs', save_folder_name, save_folder_name, 'overall_directed.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    if with_prompts and not input('continue to centrality hist?') == 'y':\n",
    "        return\n",
    "    \n",
    "    print('Plotting centrality histogram for top cases...')\n",
    "    topic_central_measures = ca.get_centrality_df(topic_dg)\n",
    "    central_cases_id = ca.get_top_k_per_measure(topic_central_measures, k = 5, cols_to_exclude=[])\n",
    "    central_cases_name = eda.convert_id_df_to_case_names(central_cases_id, True)\n",
    "    central_cases_id = central_cases_id[['in_degree']+ca.get_measures()]\n",
    "    \n",
    "    plt.figure(figsize=(14,6))\n",
    "    ca.plot_central_cases_hist(central_cases_name[['pagerank','authority_score','hub_score', 'in_degree']], color='skyblue')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(BASE_PATH.format('charts', save_folder_name, save_folder_name, 'central_case_hist.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    if with_prompts and not input('continue to yearly plots?') == 'y':\n",
    "        return\n",
    "    \n",
    "    print('Plotting yearly growth trajectory of topic...')\n",
    "    yearly_fig = gv.plot_yearly_graph(topic_df, 2000, 2017, cumulative=True, label_min_year = 2007)\n",
    "    plt.savefig(BASE_PATH.format('graphs', save_folder_name, save_folder_name, 'central_case_hist.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    if with_prompts and not input('continue to track top cases by each measure?') == 'y':\n",
    "        return\n",
    "    \n",
    "    print('Plotting growth trajectory of top cases...')\n",
    "    top_cases = set(central_cases_id.iloc[0].tolist())\n",
    "    for case in top_cases:\n",
    "        case_name = eda.get_case_name_from_id_num(case)\n",
    "        print('Getting scores for case {}'.format(case_name))\n",
    "        start, end = '20000101', '20171231'\n",
    "        case_measures_over_time = ca.get_all_case_measures_over_time(\n",
    "            topic_df, case, '20000101', '20171231', \n",
    "            measures_to_include = ['in_degree_cent',\n",
    "                'pagerank',\n",
    "                'hub_score',\n",
    "                'authority_score',\n",
    "            ]\n",
    "        )\n",
    "        fig, ax = ca.plot_case_measures_over_time(case_measures_over_time, start, end)\n",
    "        plt.title(case_name)\n",
    "        plt.savefig(BASE_PATH.format('charts', save_folder_name, save_folder_name, '{}.png'.format(' '.join(case_name.split()[0:2]))))\n",
    "        plt.show()\n",
    "    \n",
    "    return central_cases_id, top_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "contract_central_cases, contract_top_cases = analyze_one_topic(edge_df, 'contract', 'citing_has_topic_contract', with_prompts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contract_central_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eda.convert_id_df_to_case_names(contract_central_cases)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 64 bit",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
